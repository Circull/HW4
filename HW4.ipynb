{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6acf7-46a6-44a8-868c-bb8559a31d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\tОбучите модель на наборе данных Titanic и используйте различные стратегии перевзвешивания классов (например, oversampling, undersampling). \n",
    "# Сравните результаты.\n",
    "# survival: 0 = No, 1 = Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78b1d9f-7bf3-4aab-88a9-cff4fed6bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5012\\2683757671.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tit_dset_norm0 = tit_dset_norm0.replace({'male': 0, 'female': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age\n",
      "0         0       3    0   22\n",
      "1         1       1    1   38\n",
      "2         1       3    1   26\n",
      "     Sex  Age  Pclass\n",
      "873    0   47       3\n",
      "736    1   48       3\n",
      "100    1   28       3\n",
      "873    0\n",
      "736    0\n",
      "100    0\n",
      "Name: Survived, dtype: int64\n",
      "Баланс классов:  Survived\n",
      "0    424\n",
      "1    290\n",
      "Name: count, dtype: int64\n",
      "Градиентный бустинг:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       128\n",
      "           1       0.79      0.69      0.74        87\n",
      "\n",
      "    accuracy                           0.80       215\n",
      "   macro avg       0.80      0.78      0.79       215\n",
      "weighted avg       0.80      0.80      0.80       215\n",
      "\n",
      "Деревья решений:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       128\n",
      "           1       0.77      0.67      0.72        87\n",
      "\n",
      "    accuracy                           0.79       215\n",
      "   macro avg       0.78      0.77      0.77       215\n",
      "weighted avg       0.78      0.79      0.78       215\n",
      "\n",
      "К ближайших соседей:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       128\n",
      "           1       0.79      0.66      0.72        87\n",
      "\n",
      "    accuracy                           0.79       215\n",
      "   macro avg       0.79      0.77      0.78       215\n",
      "weighted avg       0.79      0.79      0.79       215\n",
      "\n",
      "Градиентный бустинг после балансировки данных Oversampling:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       128\n",
      "           1       0.72      0.71      0.72        87\n",
      "\n",
      "    accuracy                           0.77       215\n",
      "   macro avg       0.76      0.76      0.76       215\n",
      "weighted avg       0.77      0.77      0.77       215\n",
      "\n",
      "Деревья решений после балансировки данных Oversampling:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       128\n",
      "           1       0.74      0.75      0.74        87\n",
      "\n",
      "    accuracy                           0.79       215\n",
      "   macro avg       0.78      0.78      0.78       215\n",
      "weighted avg       0.79      0.79      0.79       215\n",
      "\n",
      "К ближайших соседей после балансировки данных Oversampling:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80       128\n",
      "           1       0.70      0.68      0.69        87\n",
      "\n",
      "    accuracy                           0.75       215\n",
      "   macro avg       0.74      0.74      0.74       215\n",
      "weighted avg       0.75      0.75      0.75       215\n",
      "\n",
      "Градиентный бустинг после балансировки данных Undersampling:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82       128\n",
      "           1       0.71      0.80      0.76        87\n",
      "\n",
      "    accuracy                           0.79       215\n",
      "   macro avg       0.78      0.79      0.79       215\n",
      "weighted avg       0.80      0.79      0.79       215\n",
      "\n",
      "Деревья решений после балансировки данных Undersampling:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       128\n",
      "           1       0.69      0.71      0.70        87\n",
      "\n",
      "    accuracy                           0.75       215\n",
      "   macro avg       0.74      0.75      0.75       215\n",
      "weighted avg       0.76      0.75      0.75       215\n",
      "\n",
      "К ближайших соседей после балансировки данных Undersampling:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       128\n",
      "           1       0.73      0.68      0.70        87\n",
      "\n",
      "    accuracy                           0.77       215\n",
      "   macro avg       0.76      0.75      0.76       215\n",
      "weighted avg       0.77      0.77      0.77       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "tit_dset = pd.read_excel('Titanic.xls')\n",
    "# подготовка таблицы: удаляем ненужные столбцы\n",
    "tit_dset_norm0 = tit_dset.drop(columns = ['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'])\n",
    "# подготовка таблицы: в столбце \"Sex\" заменяем строковые данные на числовые\n",
    "tit_dset_norm0 = tit_dset_norm0.replace({'male': 0, 'female': 1})\n",
    "# подготовка таблицы: удаляем все строки с пустыми данными NaN\n",
    "tit_dset_norm0 = tit_dset_norm0.dropna()\n",
    "# подготовка таблицы: в столбце 'Age' преобразовываем данные float в int\n",
    "tit_dset_norm0['Age'] = tit_dset_norm0['Age'].astype (int)\n",
    "print(tit_dset_norm0[0:3])\n",
    "tit_dset_norm0.dtypes\n",
    "# Определяем принадлежность столбцов таблицы к признакам и к целевой переменной \n",
    "X = tit_dset_norm0[['Sex', 'Age', 'Pclass']]\n",
    "y = tit_dset_norm0['Survived']\n",
    "# Разделяем данные на тестовую и обучающую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42, stratify=y)\n",
    "print(X_test[0:3])\n",
    "print(y_test[0:3])\n",
    "balance = tit_dset_norm0['Survived'].value_counts()\n",
    "print ('Баланс классов: ', balance)\n",
    "\n",
    "# Классификатор градиентного бустинга\n",
    "def GradientBoosting (X_train, X_test, y_train, y_test):\n",
    "    gb_cl = GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "    gb_cl.fit(X_train, y_train)\n",
    "    gb_pred = gb_cl.predict(X_test)\n",
    "    report = classification_report(y_test, gb_pred)\n",
    "    return report\n",
    "print (\"Градиентный бустинг: \", GradientBoosting(X_train, X_test, y_train, y_test))\n",
    "\n",
    "# Классификатор Деревья решений\n",
    "def DecisionTree (X_train, X_test, y_train, y_test):\n",
    "    DT_cl = DecisionTreeClassifier()\n",
    "    DT_cl.fit(X_train, y_train)\n",
    "    DT_pred = DT_cl.predict(X_test)\n",
    "    report = classification_report(y_test, DT_pred)\n",
    "    return report\n",
    "print (\"Деревья решений: \", DecisionTree(X_train, X_test, y_train, y_test))\n",
    "\n",
    "# Классификатор К ближайших соседей\n",
    "def KNeighbors (X_train, X_test, y_train, y_test):\n",
    "    KN_cl = KNeighborsClassifier(n_neighbors=5)\n",
    "    KN_cl.fit(X_train, y_train)\n",
    "    KN_pred = KN_cl.predict(X_test)\n",
    "    report = classification_report(y_test, KN_pred)\n",
    "    return report\n",
    "print (\"К ближайших соседей: \", KNeighbors(X_train, X_test, y_train, y_test))\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# Увеличиваем количество объектов класса-меньшинства (OverSampling)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "print (\"Градиентный бустинг после балансировки данных Oversampling: \", GradientBoosting(X_resampled, X_test, y_resampled, y_test))\n",
    "print (\"Деревья решений после балансировки данных Oversampling: \", DecisionTree(X_resampled, X_test, y_resampled, y_test))\n",
    "print (\"К ближайших соседей после балансировки данных Oversampling: \", KNeighbors(X_resampled, X_test, y_resampled, y_test))\n",
    "\n",
    "\n",
    "# Уменьшаем количество объектов класса-большинства (UnderSampling)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "print (\"Градиентный бустинг после балансировки данных Undersampling: \", GradientBoosting(X_resampled, X_test, y_resampled, y_test))\n",
    "print (\"Деревья решений после балансировки данных Undersampling: \", DecisionTree(X_resampled, X_test, y_resampled, y_test))\n",
    "print (\"К ближайших соседей после балансировки данных Undersampling: \", KNeighbors(X_resampled, X_test, y_resampled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36052c0-3cef-410c-9f05-26ad9da58996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
